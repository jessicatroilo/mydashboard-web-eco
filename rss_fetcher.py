import feedparser
import json
import os
import locale



from datetime import datetime, timedelta

# Configuration de la locale pour le formatage des dates en fran√ßais
locale.setlocale(locale.LC_TIME, "fr_FR.UTF-8")


CACHE_FILE = "rss_cache.json"
CACHE_DURATION_MINUTES = 10



def is_cache_valid():
    if not os.path.exists(CACHE_FILE):
        return False
    cache_mtime = datetime.fromtimestamp(os.path.getmtime(CACHE_FILE))
    return datetime.now() - cache_mtime < timedelta(minutes=CACHE_DURATION_MINUTES)

def get_articles():
    if is_cache_valid():
        with open(CACHE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
FEEDS = [
    {"name": "GreenIT", "url": "https://www.greenit.fr/feed/"},
    {"name": "Novethic", "url": "https://www.novethic.fr/rss/rss.xml"},
    {"name": "Next INpact", "url": "https://www.nextinpact.com/rss"},
    {"name": "01net", "url": "https://www.01net.com/rss/"},
    {"name": "Les Num√©riques", "url": "https://www.lesnumeriques.com/rss"},
    {"name": "Symfony", "url": "https://symfony.com/blog/rss.xml"},
    {"name": "Code du Garage", "url": "https://code-garage.com/blog/rss"},
]

SOURCE_STYLE = {
    "GreenIT": {"color": "border-green-400", "icon": "üå±"},
    "Novethic": {"color": "border-blue-400", "icon": "üìò"},
    "Next INpact": {"color": "border-indigo-400", "icon": "‚öôÔ∏è"},
    "01net": {"color": "border-red-400", "icon": "üíª"},
    "Les Num√©riques": {"color": "border-yellow-400", "icon": "üì∑"},
    "Code du Garage": {"color": "border-gray-400 ", "icon": "üß∞"},
    "Symfony": {"color": "border-purple-400", "icon": "üß©"},
}

def get_articles():
    articles = []
    for feed in FEEDS:
        parsed_feed = feedparser.parse(feed["url"])
        source_style = SOURCE_STYLE.get(feed["name"], {"color": "bg-gray-100", "icon": "üì∞"})
        print(f"--- {feed['name']} ---")
        print(f"Nombre d'articles r√©cup√©r√©s : {len(parsed_feed.entries)}")
        for entry in parsed_feed.entries[:3]:  # Limite √† 3 articles par flux
            
            articles.append({
                "title": entry.title,
                "link": entry.link,
                "image": entry.image if hasattr(entry, 'image') else None,
                "summary": entry.summary,
                "published": entry.published if hasattr(entry, 'published') else entry.updated,
                "published_parsed": entry.published_parsed if hasattr(entry, 'published_parsed') else entry.updated_parsed,
                "published_str": datetime(*entry.published_parsed[:6]).strftime("%A %d %B %Y √† %H:%M") if hasattr(entry, 'published_parsed') else datetime(*entry.updated_parsed[:6]).strftime("%A %d %B %Y √† %H:%M"),
                "source": feed["name"],
                "color": source_style["color"],
                "icon": source_style["icon"]
            })
    
    # On trie les articles apr√®s avoir tous r√©cup√©r√©s
    articles.sort(key=lambda x: x["published"], reverse=True)

    # Sauvegarde dans le cache
    with open(CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump(articles, f, ensure_ascii=False)

    return articles